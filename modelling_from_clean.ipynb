{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim import similarities\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import clean subreddit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_data = pd.read_csv(\"data/2019-11-02_reddit-data-learnmath_scrubbed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>discussion_topic_title</th>\n",
       "      <th>discussion_topic_message</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>thread_ref_link</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>list of websites ebooks downloads etc for mobi...</td>\n",
       "      <td>feel free to suggest more   videos   all level...</td>\n",
       "      <td>547</td>\n",
       "      <td>https://www.reddit.com/r/learnmath/comments/8p...</td>\n",
       "      <td>list of websites ebooks downloads etc for mobi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>reintroducing rorbibliographies</td>\n",
       "      <td>hi  im the new mod for orrorbibliographies i r...</td>\n",
       "      <td>141</td>\n",
       "      <td>https://www.reddit.com/r/learnmath/comments/ak...</td>\n",
       "      <td>reintroducing rorbibliographies hi  im the new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>man has walked into a casino with 1000 to play...</td>\n",
       "      <td>i translated this problem from other language ...</td>\n",
       "      <td>78</td>\n",
       "      <td>https://www.reddit.com/r/learnmath/comments/dq...</td>\n",
       "      <td>man has walked into a casino with 1000 to play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>i guys my post was removed on orrormath so i a...</td>\n",
       "      <td>to give a little bit of my background about my...</td>\n",
       "      <td>22</td>\n",
       "      <td>https://www.reddit.com/r/learnmath/comments/dq...</td>\n",
       "      <td>i guys my post was removed on orrormath so i a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>college how to avoid being daunted by the work...</td>\n",
       "      <td>hi i am a late learner of collegelevel math an...</td>\n",
       "      <td>12</td>\n",
       "      <td>https://www.reddit.com/r/learnmath/comments/dq...</td>\n",
       "      <td>college how to avoid being daunted by the work...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             discussion_topic_title  \\\n",
       "0           0  list of websites ebooks downloads etc for mobi...   \n",
       "1           1                    reintroducing rorbibliographies   \n",
       "2           2  man has walked into a casino with 1000 to play...   \n",
       "3           3  i guys my post was removed on orrormath so i a...   \n",
       "4           4  college how to avoid being daunted by the work...   \n",
       "\n",
       "                            discussion_topic_message  upvotes  \\\n",
       "0  feel free to suggest more   videos   all level...      547   \n",
       "1  hi  im the new mod for orrorbibliographies i r...      141   \n",
       "2  i translated this problem from other language ...       78   \n",
       "3  to give a little bit of my background about my...       22   \n",
       "4  hi i am a late learner of collegelevel math an...       12   \n",
       "\n",
       "                                     thread_ref_link  \\\n",
       "0  https://www.reddit.com/r/learnmath/comments/8p...   \n",
       "1  https://www.reddit.com/r/learnmath/comments/ak...   \n",
       "2  https://www.reddit.com/r/learnmath/comments/dq...   \n",
       "3  https://www.reddit.com/r/learnmath/comments/dq...   \n",
       "4  https://www.reddit.com/r/learnmath/comments/dq...   \n",
       "\n",
       "                                            combined  \n",
       "0  list of websites ebooks downloads etc for mobi...  \n",
       "1  reintroducing rorbibliographies hi  im the new...  \n",
       "2  man has walked into a casino with 1000 to play...  \n",
       "3  i guys my post was removed on orrormath so i a...  \n",
       "4  college how to avoid being daunted by the work...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'list of websites ebooks downloads etc for mobile users and people too lazy to read the sidebar'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data[\"discussion_topic_title\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_data = reddit_data[\"discussion_topic_title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a list \n",
    "corpus_text = list()\n",
    "for row in range(reddit_data.shape[0]):\n",
    "    temp = reddit_data.iloc[row]\n",
    "    corpus_text.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1 , 2 ,3 ,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: x**2, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'list of websites ebooks downloads etc for mobile users and people too lazy to read the sidebar'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a string into a list of words, to generate a list of lists\n",
    "# clean words and remove stop words\n",
    "\n",
    "processed_corpus = list()\n",
    "porter=PorterStemmer()\n",
    "\n",
    "for text in corpus_text:\n",
    "    \n",
    "    token_words=word_tokenize(text)\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "        \n",
    "    # tokenize it \n",
    "    tokenized_list = word_tokenize(text)\n",
    "    \n",
    "    # convert to lower case\n",
    "    tokenized_list = [w.lower() for w in stem_sentence]\n",
    "    \n",
    "    # get the alphabetic words\n",
    "    words = [word for word in tokenized_list if word.isalpha()]\n",
    "    \n",
    "    # get rid of stop words \n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    \n",
    "    # stemming\n",
    "    lambda x: x\n",
    "            \n",
    "    processed_corpus.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['list',\n",
       " 'websit',\n",
       " 'ebook',\n",
       " 'download',\n",
       " 'etc',\n",
       " 'mobil',\n",
       " 'user',\n",
       " 'peopl',\n",
       " 'lazi',\n",
       " 'read',\n",
       " 'sidebar']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(1452 unique tokens: ['download', 'ebook', 'etc', 'lazi', 'list']...)\n"
     ]
    }
   ],
   "source": [
    "# create dictionary\n",
    "dictionary_reddit = corpora.Dictionary(processed_corpus)\n",
    "print(dictionary_reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(1829 unique tokens: ['downloads', 'ebooks', 'etc', 'lazy', 'list']...)\n"
     ]
    }
   ],
   "source": [
    "# create dictionary\n",
    "dictionary_reddit = corpora.Dictionary(processed_corpus)\n",
    "print(dictionary_reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to a bag of words reprensentation\n",
    "bow_corpus_reddit = [dictionary_reddit.doc2bow(text) for text in processed_corpus]\n",
    "#pprint.pprint(bow_corpus_reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "tfidf_reddit = models.TfidfModel(bow_corpus_reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarities indexing\n",
    "index_reddit = similarities.SparseMatrixSimilarity(tfidf_reddit[bow_corpus_reddit], num_features = 1829)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test a query\n",
    "query_document = 'how to do differential equation'\n",
    "token_words=word_tokenize(query_document)\n",
    "stem_sentence=[]\n",
    "for word in token_words:\n",
    "    stem_sentence.append(porter.stem(word))\n",
    "# bag of words representation of the query\n",
    "query_bow = dictionary_reddit.doc2bow(stem_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the similarities scores\n",
    "sims_reddit = index_reddit[tfidf_reddit[query_bow]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put scores in a dict\n",
    "sim_scores = dict()\n",
    "for document_number, score in sorted(enumerate(sims_reddit)):\n",
    "    sim_scores[document_number] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the scores\n",
    "sorted_sim_scores = sorted(sim_scores.items(), key=lambda kv: kv[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what is an equation'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(402, 1.0),\n",
       " (460, 1.0),\n",
       " (364, 0.8363477),\n",
       " (102, 0.63148826),\n",
       " (16, 0.62982845),\n",
       " (754, 0.56039983),\n",
       " (403, 0.5006765),\n",
       " (147, 0.49865982),\n",
       " (226, 0.49456146),\n",
       " (236, 0.46900314)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_sim_scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(460, 0.99999994),\n",
       " (102, 0.66516),\n",
       " (754, 0.6157832),\n",
       " (402, 0.5454679),\n",
       " (209, 0.4805221),\n",
       " (364, 0.4607327),\n",
       " (412, 0.42027405),\n",
       " (878, 0.3622085),\n",
       " (376, 0.35159275),\n",
       " (933, 0.34474713)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_sim_scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'differential equation'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data[460]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what is an equation'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data[102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'non linear differential equation'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data[754]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'differential equations'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data[402]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'advanced calculus general solution of a differential equation'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data[209]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This cell is to remove words with freq = 1, MIGHT SKIP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count word frequencies\n",
    "frequency = defaultdict(int)\n",
    "for text in processed_corpus:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "# Only keep words that appear more than once (remove for now)\n",
    "#processed_corpus = token for token in texts_clean if frequency[token] > 1\n",
    "processed_corpus = [[token for token in text if frequency[token] > 1] for text in processed_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['list',\n",
       " 'websites',\n",
       " 'ebooks',\n",
       " 'downloads',\n",
       " 'etc',\n",
       " 'mobile',\n",
       " 'users',\n",
       " 'people',\n",
       " 'lazy',\n",
       " 'read',\n",
       " 'sidebar']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_corpus[0] # will be different from above if have removed freq = 1 words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
